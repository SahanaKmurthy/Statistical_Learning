suppressMessages(library(tidyverse))
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
df$y    <- df$Cost       # create a new column on the fly
df %>% select(.,-Cost) -> df
summary(df)
# FILL ME IN WITH CODE
set.seed(100)
s <- sample(nrow(df), round(0.7*nrow(df)))
df.train <- df[s,]
df.test <- df[-s,]
# FILL ME IN WITH CODE
lm.out <- lm(y~. , data = df.train)
summary(lm.out)
print(summary(lm.out)$adj.r.squared)
# FILL ME IN WITH CODE
lm.out <- lm(y~. , data = df.train)
print(summary(lm.out)$adj.r.squared)
install.packages("bestglm")
# FILL ME IN WITH CODE
library(bestglm)
big.bic <- bestglm(df.train , IC = 'BIC')
big.aic <- bestglm(df.train , IC = 'AIC')
# FILL ME IN WITH CODE
library(bestglm)
big.bic <- bestglm(df.train , family = 'gaussian' , IC = 'BIC')
# FILL ME IN WITH CODE
library(bestglm)
big.bic <- bestglm(df.train , family = 'gaussian' , IC = "BIC")
# FILL ME IN WITH CODE
library(bestglm)
big.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
big.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
# FILL ME IN WITH CODE
library(bestglm)
big.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(big.bic$BestModels)
big.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(big.aic$BestModels)
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
print(aic_predictors)
# Coefficients of BIC model
print(coef(bg.bic$BestModel))
# Coefficients of AIC model
print(coef(bg.aic$BestModel))
# FILL ME IN WITH CODE
# Predictions for BIC model
bic_predictions <- predict(bg.bic$BestModel, newdata = df.test)
# Predictions for AIC model
aic_predictions <- predict(bg.aic$BestModel, newdata = df.test)
# Mean Squared Error for BIC model
bic_mse <- mean((df.test$Cost - bic_predictions)^2)
print(bic_mse)
# Mean Squared Error for AIC model
aic_mse <- mean((df.test$Cost - aic_predictions)^2)
print(aic_mse)
# Predictions from linear regression model
lm_predictions <- predict(lm_model, newdata = df.test)
# FILL ME IN WITH CODE
# Predictions for BIC model
bic_predictions <- predict(bg.bic$BestModel, newdata = df.test)
# Predictions for AIC model
aic_predictions <- predict(bg.aic$BestModel, newdata = df.test)
# Mean Squared Error for BIC model
bic_mse <- mean((df.test$Cost - bic_predictions)^2)
print(bic_mse)
# Mean Squared Error for AIC model
aic_mse <- mean((df.test$Cost - aic_predictions)^2)
print(aic_mse)
# Predictions from linear regression model
lm_predictions <- predict(lm.out, newdata = df.test)
# Mean Squared Error for linear regression model
lm_mse <- mean((df.test$Cost - lm_predictions)^2)
print(lm_mse)
# FILL ME IN WITH CODE
# Predictions for BIC model
bic_predictions <- predict(bg.bic$BestModel, newdata = df.test)
# Predictions for AIC model
aic_predictions <- predict(bg.aic$BestModel, newdata = df.test)
# Mean Squared Error for BIC model
bic_mse <- mean((df.test$Cost - bic_predictions)^2)
print(bic_mse)
# Mean Squared Error for AIC model
aic_mse <- mean((df.test$Cost - aic_predictions)^2)
print(aic_mse)
# FILL ME IN WITH CODE
# Predictions for BIC model
bic_predictions <- predict(bg.bic$BestModel, newdata = df.test)
# Predictions for AIC model
aic_predictions <- predict(bg.aic$BestModel, newdata = df.test)
# Mean Squared Error for BIC model
bic_mse <- mean((df.test$y - bic_predictions)^2)
print(bic_mse)
# Mean Squared Error for AIC model
aic_mse <- mean((df.test$y - aic_predictions)^2)
print(aic_mse)
bic    <- bg.bic$Subsets["BIC"]
df.bic <- data.frame("p"=1:ncol(df.train)-1,"BIC"=bic[,1])
g <- ggplot(data=df.bic,mapping=aes(x=p,y=BIC)) +
geom_point(size=1.5,color="blue") +
geom_line(color="blue") +
ylim(min(bic),min(bic+100))  # a quick and dirty way to try to hone in on the right range to see minimum
suppressWarnings(print(g)) # a way to get around pesky ggplot warnings
# FILL ME IN WITH CODE
summary(bg.bic$BestModels)
suppressMessages(library(tidyverse))
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
df$y    <- df$Cost       # create a new column on the fly
df %>% select(.,-Cost) -> df
summary(df)
# FILL ME IN WITH CODE
set.seed(100)
s <- sample(nrow(df), round(0.7*nrow(df)))
df.train <- df[s,]
df.test <- df[-s,]
# FILL ME IN WITH CODE
lm.out <- lm(y~. , data = df.train)
print(summary(lm.out)$adj.r.squared)
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
print(aic_predictors)
# Coefficients of BIC model
print(coef(bg.bic$BestModel))
# Coefficients of AIC model
print(coef(bg.aic$BestModel))
?bestglm
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
print(aic_predictors)
# Coefficients of BIC model
print(coef(bg.bic$BestModel))
print(names(bg.bic))
# Coefficients of AIC model
print(coef(bg.aic$BestModel))
print(names(bg.aic))
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
print(aic_predictors)
# Coefficients of BIC model
# print(coef(bg.bic$BestModel))
print(names(bg.bic))
# Coefficients of AIC model
# (coef(bg.aic$BestModel))
print(names(bg.aic))
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
# print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
# print(aic_predictors)
# Coefficients of BIC model
# print(coef(bg.bic$BestModel))
print(names(bg.bic))
# Coefficients of AIC model
# (coef(bg.aic$BestModel))
print(names(bg.aic))
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
# print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
# print(aic_predictors)
# Coefficients of BIC model
# print(coef(bg.bic$BestModel))
print(names(bg.bic$BestModels))
# Coefficients of AIC model
# (coef(bg.aic$BestModel))
print(names(bg.aic$BestModels))
# FILL ME IN WITH CODE
library(bestglm)
bg.bic <- bestglm(df.train , family = gaussian , IC = "BIC")
print(bg.bic$BestModels)
bg.aic <- bestglm(df.train , family = gaussian , IC = 'AIC')
print(bg.aic$BestModels)
bic_predictors <- length(coef(bg.bic$BestModels)) - 1
print(bic_predictors)
aic_predictors <- length(coef(bg.aic$BestModels)) - 1
print(aic_predictors)
# Coefficients of BIC model
print(coef(bg.bic$BestModel))
# Coefficients of AIC model
(coef(bg.aic$BestModel))
# FILL ME IN WITH CODE
library(bestglm)
# Best subset selection using BIC
bg.bic <- bestglm(df.train, family = gaussian, IC = "BIC")
print(bg.bic$BestModel)  # Access best model for BIC
# Best subset selection using AIC
bg.aic <- bestglm(df.train, family = gaussian, IC = "AIC")
print(bg.aic$BestModel)  # Access best model for AIC
# Number of predictors in BIC-selected model (excluding intercept)
bic_predictors <- length(coef(bg.bic$BestModel)) - 1
print(bic_predictors)
# Number of predictors in AIC-selected model (excluding intercept)
aic_predictors <- length(coef(bg.aic$BestModel)) - 1
print(aic_predictors)
# Coefficients of BIC model
print(coef(bg.bic$BestModel))
# Coefficients of AIC model
print(coef(bg.aic$BestModel))
# FILL ME IN WITH CODE
# Predictions for BIC model
bic_predictions <- predict(bg.bic$BestModel, newdata = df.test)
# Predictions for AIC model
aic_predictions <- predict(bg.aic$BestModel, newdata = df.test)
# Mean Squared Error for BIC model
bic_mse <- mean((df.test$y - bic_predictions)^2)
print(bic_mse)
# Mean Squared Error for AIC model
aic_mse <- mean((df.test$y - aic_predictions)^2)
print(aic_mse)
bic    <- bg.bic$Subsets["BIC"]
df.bic <- data.frame("p"=1:ncol(df.train)-1,"BIC"=bic[,1])
g <- ggplot(data=df.bic,mapping=aes(x=p,y=BIC)) +
geom_point(size=1.5,color="blue") +
geom_line(color="blue") +
ylim(min(bic),min(bic+100))  # a quick and dirty way to try to hone in on the right range to see minimum
suppressWarnings(print(g)) # a way to get around pesky ggplot warnings
# FILL ME IN WITH CODE
summary(bg.bic$BestModels)
# FILL ME IN WITH CODE
summary(bg.bic$BestModel)
