---
title: "Lab: Random Forest and Boosting"
author: "36-600"
output: 
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
---

# Regression

We import the heart-disease dataset and log-transform the response variable, `Cost`:
```{r}
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
```

## Question 1

Split these data into training and test sets, reusing the random-number-generator seed you used in previous labs when analyzing these data.
```{r}
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
```

## Question 2

Learn a random forest model given the training data, and compute the MSE. Remember to set `importance=TRUE`. **Note: for reproducible results, set the seed before running random forest!** Assuming you split the data in the same manner as you did before, feel free to look back at your other labs and see if the MSE is smaller here. (For me and my split? It is...about 10% smaller than for a regression tree.)
```{r}
# REPLACE ME WITH CODE
library(randomForest)
set.seed(100)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df.test$Cost) - as.numeric(resp.pred))^2)
print(mse)
```

## Question 3

Create the variable importance plot. Remember to pass `type=1` as an argument to this plot. Mentally note the important variables. These should be consistent with those variables that appeared in your regression tree in the tree lab.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
library(randomForest)
#(mean((resp.pred-df.test$Cost)^2),3)
varImpPlot(rf.out,type=1)
```

## Question 4

Show the diagnostic plot of predicted test-set response values vs. observed test-set response values. As usual, make sure the limits are the same along both axes and plot a diagonal line with slope 1.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
library(ggplot2)
ggplot(data = data.frame("x" = df.test$Cost, "y" = resp.pred), aes(x = x, y = y)) +
  geom_point(size = 0.5, color = "saddlebrown") +
  coord_equal() +  # Ensures equal scaling of x and y axes
  geom_abline(intercept = 0, slope = 1, color = "red", linetype = "dashed") +
  labs(x = "Observed Cost", y = "Predicted Cost") +
  theme_minimal()
```

## Question 5

Now learn an extreme gradient boosting model, and show the test-set MSE. Note that in order to do this, we have to remove the variables `Gender`, `Drugs`, and `Complications`, which are factor or factor-like variables, and for ease of code implementation, we will break up `df.train` and `df.test` into predictor and response variables:
```{r}
suppressMessages(library(dplyr))
df.train %>% dplyr::select(.,-Gender,-Drugs,-Complications) -> df.train
df.test  %>% dplyr::select(.,-Gender,-Drugs,-Complications) -> df.test
resp.train <- df.train[,1]
resp.test  <- df.test[,1]
pred.train <- df.train[,-1]
pred.test  <- df.test[,-1]
```
Note that by doing this, the MSE that we get might not be as good as for random forest. But we'll see!
```{r}
# REPLACE ME WITH CODE
suppressMessages(library(xgboost))

train <- xgb.DMatrix(data=as.matrix(df.train[,2:6]),label=df.train$Cost)
test <- xgb.DMatrix(data=as.matrix(df.test[,2:6]),label=df.test$Cost)
xgb.cv.out <- xgb.cv(params=list(objective="reg:squarederror"),train,nrounds=30,nfold=5,verbose=0)
rmse.min <- xgb.cv.out$evaluation_log$test_rmse_mean
cat("The optimal number of trees is ",which.min(rmse.min),"\n")

xgb.out <- xgboost(train,nrounds=which.min(rmse.min),params=list(objective="reg:squarederror"),verbose=0)
resp.pred <- predict(xgb.out,newdata=test)

# Calculate Mean Squared Error (MSE) on test set
mse <- mean((resp.test - resp.pred)^2)
mse
```

## Question 6

Create a variable importance plot for the extreme gradient boosting model. Make a mental note about whether the variables identified as important here are also the more important ones identified by random forest.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
imp.out <- xgb.importance(model=xgb.out)
xgb.plot.importance(importance_matrix=imp.out,col="blue")
```

---

# Classification

We will now load in the data on political movements that you looked at in previous labs:
```{r}
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
  n               <- length(variable)
  new.variable    <- rep(level0,n)
  w               <- which(variable==1)
  new.variable[w] <- level1
  return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
```

Note that given the number of factor variables in this dataset, we'll forego learning a boosting model below.

## Question 7

Split the data! Recreate what you did for previous labs, including the random-number-generator seed.
```{r}
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))

df.train <- df[s,]
df.test <- df[-s,]
```

## Question 8

Learn a random forest model. Output probabilities for Class 1 (see the notes!) but do not output a confusion matrix or output a misclassification rate. It will become clear why we will hold off on computing this quantities for now... However, having said all this, do go ahead and plot the variable importance plot here.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred

varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
```

## Question 9

Plot a ROC curve for random forest, and output the AUC value.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH 
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)

# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)

# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
```

## Question 10

Use Youden's $J$ statistic to determine the optimal class-separation threshold. Output that number. Then, using that threshold, transform the test-set Class 1 probabilities to class predictions, and output the confusion matrix and the misclassification rate. (Note: you can reuse code from previous labs.)
```{r}
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")

# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")

# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("SUCCESS", "FAILURE"))
df.test$label <- factor(df.test$label, levels = c("SUCCESS", "FAILURE"))

# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)

# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
```

