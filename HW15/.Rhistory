load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred
varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
# REPLACE ME WITH
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)
# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)
# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, 1, 0)
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c(0, 1))
df.test$label <- factor(df.test$label, levels = c(0, 1))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test , type = "response")
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(1)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(111)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(1)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
library(randomForest)
set.seed(100)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(1)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred
varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
# REPLACE ME WITH
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)
# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)
# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c(0, 1))
df.test$label <- factor(df.test$label, levels = c(0, 1))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("FAILURE", "SUCCESS"))
df.test$label <- factor(df.test$label, levels = c("FAILURE", "SUCCESS"))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("SUCCESS", "FAILURE"))
df.test$label <- factor(df.test$label, levels = c("SUCCESS", "FAILURE"))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
# Check if both levels are present in predictions and actual labels
print(table(class.pred))
print(table(df.test$label))
# Check if both levels are present in predictions and actual labels
print(table(class.pred))
print(table(df.test$label))
unique(df.test$label)
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
summary(df.train)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
summary(df.test)
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred
varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
# REPLACE ME WITH
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)
# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)
# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("SUCCESS", "FAILURE"))
df.test$label <- factor(df.test$label, levels = c("SUCCESS", "FAILURE"))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(1)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(10)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
library(randomForest)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
# REPLACE ME WITH CODE
library(randomForest)
set.seed(100)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df$Cost) - as.numeric(resp.pred))^2)
print(mse)
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(1000)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred
varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
# REPLACE ME WITH
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)
# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)
# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("SUCCESS", "FAILURE"))
df.test$label <- factor(df.test$label, levels = c("SUCCESS", "FAILURE"))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
suppressMessages(library(randomForest))
rf.out = randomForest(label~.,data=df.train,
importance=TRUE)
out.pred = predict(rf.out,newdata=df.test,type="prob")[,2]
out.pred
varImpPlot(rf.out, type = 1, main = "Random Forest Variable Importance")
# REPLACE ME WITH
suppressMessages(library(pROC))
roc_obj <- roc(df.test$label, out.pred)
# Plot ROC curve
plot(roc_obj, col = "blue", main = "ROC Curve for Random Forest", lwd = 2)
abline(a = 0, b = 1, col = "red", lty = 2)
# Output the AUC value
auc_value <- auc(roc_obj)
cat("AUC:", auc_value, "\n")
# REPLACE ME WITH CODE
# Load necessary libraries
library(pROC)
library(caret)
# Use Youden's J statistic to find the optimal threshold
J <- roc_obj$sensitivities + roc_obj$specificities - 1
w <- which.max(J)
optimal_threshold <- roc_obj$thresholds[w]
cat("Optimal threshold (Youden's J):", round(optimal_threshold, 3), "\n")
# Transform test-set Class 1 probabilities to class predictions based on the optimal threshold
class.pred <- ifelse(out.pred >= optimal_threshold, "SUCCESS", "FAILURE")
# Ensure predictions and labels have the same levels
class.pred <- factor(class.pred, levels = c("SUCCESS", "FAILURE"))
df.test$label <- factor(df.test$label, levels = c("SUCCESS", "FAILURE"))
# Calculate the confusion matrix
conf_matrix <- confusionMatrix(class.pred, df.test$label)
cat("Confusion Matrix:\n")
print(conf_matrix$table)
# Calculate the misclassification rate
misclassification_rate <- 1 - sum(diag(conf_matrix$table)) / sum(conf_matrix$table)
cat("Misclassification Rate:", round(misclassification_rate, 3), "\n")
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(length(df$Cost) * 0.7))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
library(randomForest)
set.seed(100)
rf.out <- randomForest(Cost ~ ., data = df.train , importance = TRUE)
resp.pred <- predict(rf.out , newdata = df.test)
mse <- mean((as.numeric(df.test$Cost) - as.numeric(resp.pred))^2)
print(mse)
