lines = readLines("http://www.stat.cmu.edu/~pfreeman/biden_2021.txt")
# FILL ME IN
length(lines)
nchar(lines)
# FILL ME IN
length(lines)
sum(nchar(lines))
# FILL ME IN
out = [gregexpr(" ", lines)]
# FILL ME IN
out = gregexpr(" ", lines)
total = 0
for ( ii in 1:length(lines) ) {
total = total+length(out[[ii]])
}
# FILL ME IN
out = gregexpr(" ", lines)
total = 0
for ( ii in 1:length(lines) ) {
total = total+length(out[[ii]])
}
print(total)
# FILL ME IN
words <- strsplit(lines , " ")
count <- numeric(length(lines))
# Loop over the list of words per line and count the number of words
for (ii in 1:length(lines)) {
word_counts[ii] <- length(words_per_line[[ii]])
}
# FILL ME IN
words <- strsplit(lines , " ")
count <- numeric(length(lines))
# Loop over the list of words per line and count the number of words
for (ii in 1:length(lines)) {
word_counts[ii] <- length(words[[ii]])
}
# FILL ME IN
words <- strsplit(lines , " ")
count <- numeric(length(lines))
# Loop over the list of words per line and count the number of words
for (ii in 1:length(lines)) {
count[ii] <- length(words[[ii]])
}
# Create a table of the number of words per line
word_count_table <- table(count)
# Display the table
word_count_table
lines = readLines("http://www.stat.cmu.edu/~pfreeman/biden_2021.txt")
# FILL ME IN
america <- sum(grepl("America" , lines))
# FILL ME IN
america <- sum(grepl("America" , lines))
america
# FILL ME IN
speech <- paste(lines , collapse = " ")
speech
# FILL ME IN
speech <- paste(lines , collapse = "Here")
speech
# FILL ME IN
speech <- paste(lines , collapse = " ")
speech
# FILL ME IN
library(stopwords)
install.packages("stopwords")
# FILL ME IN
library(stopwords)
head(stopwords("en"),10)
# FILL ME IN
suppressMessages(library(stopwords))
head(stopwords("en"),10)
# FILL ME IN
suppressMessages(library(stopwords))
head(stopwords("en"),10)
speech <- tolower(unlist(strsplit(lines,split="[ ,!\\.]")))
w <- which(nchar(speech)==0)
speech <- speech[-w] # could do speech <- speech[speech!=""] also, or dplyr...
stopword.logical <- speech %in% stopwords("en") # is element of left "in" vector at right? [T/F]
paste(speech[stopword.logical==FALSE],collapse=" ")
# FILL ME IN
suppressMessages(library(stopwords))
head(stopwords("en"),10)
speech <- tolower(unlist(strsplit(lines,split="[ ,!\\.\\?;:\\-]")))
w <- which(nchar(speech)==0)
speech <- speech[-w] # could do speech <- speech[speech!=""] also, or dplyr...
stopword.logical <- speech %in% stopwords("en") # is element of left "in" vector at right? [T/F]
paste(speech[stopword.logical==FALSE],collapse=" ")
# FILL ME IN
# Create a frequency table for the remaining words
word_frequency <- table(paste(speech[stopword.logical==FALSE],collapse=" "))
# Sort the words by their frequency in descending order
sorted_words <- sort(word_frequency, decreasing = TRUE)
# Get the top 20 most common words
top_20_words <- head(sorted_words, 20)
# Display the top 20 words
top_20_words
# FILL ME IN
# Create a frequency table for the remaining words
word_frequency <- table(unlist(paste(speech[stopword.logical==FALSE],collapse=" ")))
# Sort the words by their frequency in descending order
sorted_words <- sort(word_frequency, decreasing = TRUE)
# Get the top 20 most common words
top_20_words <- head(sorted_words, 20)
# Display the top 20 words
top_20_words
lines = readLines("http://www.stat.cmu.edu/~pfreeman/biden_2021.txt")
# FILL ME IN
length(lines)
sum(nchar(lines))
# FILL ME IN
out = gregexpr(" ", lines)
total = 0
for ( ii in 1:length(lines) ) {
total = total+length(out[[ii]])
}
print(total)
# FILL ME IN
words <- strsplit(lines , " ")
count <- numeric(length(lines))
# Loop over the list of words per line and count the number of words
for (ii in 1:length(lines)) {
count[ii] <- length(words[[ii]])
}
# Create a table of the number of words per line
word_count_table <- table(count)
# Display the table
word_count_table
# FILL ME IN
america <- sum(grepl("America" , lines))
america
# FILL ME IN
speech <- paste(lines , collapse = " ")
speech
# FILL ME IN
suppressMessages(library(stopwords))
head(stopwords("en"),10)
speech <- tolower(unlist(strsplit(lines,split="[ ,!\\.\\?;:\\-]")))
w <- which(nchar(speech)==0)
speech <- speech[-w] # could do speech <- speech[speech!=""] also, or dplyr...
stopword.logical <- speech %in% stopwords("en") # is element of left "in" vector at right? [T/F]
paste(speech[stopword.logical==FALSE],collapse=" ")
# FILL ME IN
filtered_speech <- speech[!stopword.logical]
# Create a frequency table for the remaining words
word_frequency <- table(filtered_speech)
# Sort the words by their frequency in descending order
sorted_words <- sort(word_frequency, decreasing = TRUE)
# Get the top 20 most common words
top_20_words <- head(sorted_words, 20)
# Display the top 20 words
top_20_words
