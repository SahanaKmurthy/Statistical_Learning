# Initial guesses for the parameters: [a, b, c, d, e]
# These guesses should be reasonable but not overly influenced by the observed data.
par <- c(1, 1, 0, 0, 0)
# Optimize the parameters
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
df <- read.csv("https://www.stat.cmu.edu/~pfreeman/optim_data.csv")
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
# Define the chi-square loss function for a generalized sinusoidal model
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Sinusoidal + quadratic polynomial model: y = a*sin(b*x + c) + d*x^2 + e*x + f
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Initial guesses for the parameters: [a, b, c, d, e]
# These guesses should be reasonable but not overly influenced by the observed data.
par <- c(1, 1, 0, 0, 0)
# Optimize the parameters
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Check for issues with the error term
if (any(e == 0)) stop("Error term 'e' contains zero values, which causes division by zero.")
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
# Check for non-finite values
if (!is.finite(chi_square)) stop("Chi-square calculation resulted in non-finite value.")
return(chi_square)
}
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Check for issues with the error term
if (any(e == 0)) stop("Error term 'e' contains zero values, which causes division by zero.")
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
# Check for non-finite values
if (!is.finite(chi_square)) stop("Chi-square calculation resulted in non-finite value.")
return(chi_square)
}
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 1, 0, 0, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 1, 0, 0, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 1, 1, 0, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(0, 1, 1, 0, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 0, 1, 0, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 0, 1, 0, 1, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 0, 1, 1, 0, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
suppressMessages(library(tidyverse))
fit.fun <- function(par, data) {
x <- data$x
y <- data$y
e <- data$e
# Evaluate the model
model <- par[1] * sin(par[2] * x + par[3]) + par[4] * x^2 + par[5] * x + par[6]
# Calculate chi-square
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Set initial parameter guesses
par <- c(1, 0, 1, 1, 1, 0)  # Adjust if needed
# Perform optimization
op.out <- suppressWarnings(optim(par, fit.fun, data=df, method="BFGS"))
# Extract optimized parameters
optimized_params <- op.out$par
# Print the optimized parameters and chi-square value
print(optimized_params)
print(op.out$value)
# Plot the optimized model fit with the data
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
ggplot(df, aes(x=x)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1, color="blue") +
geom_point(aes(y=y), color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1) +
labs(title="Fitted Sinusoidal + Polynomial Model", y="y", x="x")
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(0,0,0,0) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
# plot(df$x, df$y, main="Cubic Polynomial Fit", xlab="x", ylab="y")
# lines(df$x, op.out$par[1]*df$x^3 + op.out$par[2]*df$x^2 + op.out$par[3]*df$x + op.out$par[4], col="red")
set.seed(555)
x <- -5:5
y <- 0.1*x^3 - 0.5*x + 2.1 + rnorm(length(x),mean=0,sd=0.5*(1+abs(x)))
e <- 0.5*(1+abs(x))
df <- data.frame("x"=x,"y"=y,"e"=e)
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(0,0,0,0) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
# plot(df$x, df$y, main="Cubic Polynomial Fit", xlab="x", ylab="y")
# lines(df$x, op.out$par[1]*df$x^3 + op.out$par[2]*df$x^2 + op.out$par[3]*df$x + op.out$par[4], col="red")
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(1,0,0,0) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(1,1,1,1) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1] * sin(optimized_params[2] * x + optimized_params[3]) +
optimized_params[4] * x^2 +
optimized_params[5] * x +
optimized_params[6])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(1,1,1,1) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1]*x^3 +
optimized_params[2]*x^2 +
optimized_params[3]*x +
optimized_params[4])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
set.seed(555)
x <- -5:5
y <- 0.1*x^3 - 0.5*x + 2.1 + rnorm(length(x),mean=0,sd=0.5*(1+abs(x)))
e <- 0.5*(1+abs(x))
df <- data.frame("x"=x,"y"=y,"e"=e)
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
par <- c(1,1,1,1) # initial guesses for alpha, beta
op.out <- suppressWarnings(optim(par,fit.fun,data=df))
op.out$value # the minimum chi-square value
df <- df %>%
mutate(predicted_y = optimized_params[1]*x^3 +
optimized_params[2]*x^2 +
optimized_params[3]*x +
optimized_params[4])
# Plot the data points and fitted curve
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y=predicted_y), color="darkgreen", size=1)
# REPLACE ME WITH CODE
# Define the objective function to calculate chi-squared for a cubic polynomial
fit.fun <- function(par, data) {
# Extract data points and error values
x <- data$x
y <- data$y
e <- data$e
# Define the cubic polynomial model: a*x^3 + b*x^2 + c*x + d
model <- par[1]*x^3 + par[2]*x^2 + par[3]*x + par[4]
# Calculate the chi-square value
chi_square <- sum((y - model)^2 / e^2)
return(chi_square)
}
# Initial parameter guesses for a cubic polynomial (a, b, c, d)
initial_guesses <- c(1, 1, 1, 1)
# Perform optimization to estimate the parameters
op.out <- optim(par = initial_guesses, fn = fit.fun, data = df, method = "BFGS")
# Extract the optimized coefficients
optimized_params <- op.out$par
print(optimized_params)  # Display the optimized parameters
# Add the predicted values to the dataframe for plotting
df <- df %>%
mutate(predicted_y = optimized_params[1]*x^3 +
optimized_params[2]*x^2 +
optimized_params[3]*x +
optimized_params[4])
# Plot the data points, error bars, and the fitted cubic polynomial
library(ggplot2)
ggplot(data = df, aes(x = x, y = y)) +
geom_errorbar(aes(ymin = y - e, ymax = y + e), width = 0.1, color = "blue") +
geom_point(color = "firebrick") +
geom_line(aes(y = predicted_y), color = "darkgreen", size = 1) +
labs(title = "Fitted Cubic Polynomial Model", y = "y", x = "x")
