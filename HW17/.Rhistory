suppressMessages(library(tidyverse))
set.seed(555)
x <- -5:5
y <- 0.1*x^3 - 0.5*x + 2.1 + rnorm(length(x),mean=0,sd=0.5*(1+abs(x)))
e <- 0.5*(1+abs(x))
df <- data.frame("x"=x,"y"=y,"e"=e)
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((y-pr.pred)^2)
# REPLACE ME WITH CODE
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((y-pr.pred)^2)
print(mse)
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((y-pr.pred)^2)
print(mse)
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~bs(x,df = 4), data = df, weights = 1/(e^12))
install.packages("splines2")
# REPLACE ME WITH CODE
suppressMessages(library(splines))
set.seed(1)
pr.out <- lm(y~bs(x,df = 4), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# REPLACE ME WITH CODE
ss.out <- suppressWarnings(
smooth.spline(df$x,y=df$y,w=1/(df$e^2),cv=TRUE)
)
ss.out$lambda
ss.pred <- predict(ss.out)
mean((y-ss.pred$y)^2)
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mean((y-lpr.pred)^2)
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(df, aes(x = x, y = y)) +
geom_point(color = "blue", alpha = 0.6) +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
set.seed(1)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
suppressMessages(library(splines))
set.seed(1)
pr.out <- lm(y~bs(x,df = 4), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Polynomial Regression with four degrees of freedom") +
theme_minimal()
# REPLACE ME WITH CODE
ss.out <- suppressWarnings(
smooth.spline(df$x,y=df$y,w=1/(df$e^2),cv=TRUE)
)
ss.out$lambda
ss.pred <- predict(ss.out)
mean((y-ss.pred$y)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = ss.pred), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
ss.out <- suppressWarnings(
smooth.spline(df$x,y=df$y,w=1/(df$e^2),cv=TRUE)
)
ss.out$lambda
ss.pred <- predict(ss.out)
mean((y-ss.pred$y)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = ss.pred$y), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mean((y-lpr.pred)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred$y), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mean((y-lpr.pred)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mean((y-lpr.pred)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred), color = "red", size = 1) +
ggtitle("Local Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mse_lpr <- mean((df$y - lpr.pred)^2)
print(mse_lpr)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred), color = "red", size = 1) +
ggtitle("Local Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
p <- predict(lpr.out,se=TRUE)
# Compute Mean Squared Error (MSE) as before (optional)
mse_lpr <- mean((df$y - p$fit)^2)
print(mse_lpr)
# Plot the data with error bars, the regression line, and the confidence band
ggplot(data = df, mapping = aes(x = x, y = y)) +
geom_errorbar(aes(ymin = y - e, ymax = y + e), width = 0.1, color = "blue") +
geom_point(color = "firebrick") +
geom_line(aes(y = p$fit), color = "red", size = 1) +
geom_line(aes(x = lpr.out$x, y = p$fit + p$se.fit), color = "purple", linetype = "dashed") +
geom_line(aes(x = lpr.out$x, y = p$fit - p$se.fit), color = "purple", linetype = "dashed") +
ggtitle("Local Polynomial Regression with Confidence Band") +
theme_minimal()
suppressMessages(library(tidyverse))
set.seed(555)
x <- -5:5
y <- 0.1*x^3 - 0.5*x + 2.1 + rnorm(length(x),mean=0,sd=0.5*(1+abs(x)))
e <- 0.5*(1+abs(x))
df <- data.frame("x"=x,"y"=y,"e"=e)
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
set.seed(10)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
suppressMessages(library(splines))
set.seed(1)
pr.out <- lm(y~bs(x,df = 4), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Polynomial Regression with four degrees of freedom") +
theme_minimal()
# REPLACE ME WITH CODE
ss.out <- suppressWarnings(
smooth.spline(df$x,y=df$y,w=1/(df$e^2),cv=TRUE)
)
ss.out$lambda
ss.pred <- predict(ss.out)
mean((y-ss.pred$y)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = ss.pred$y), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mse_lpr <- mean((df$y - lpr.pred)^2)
print(mse_lpr)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred), color = "red", size = 1) +
ggtitle("Local Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
p <- predict(lpr.out,se=TRUE)
# Compute Mean Squared Error (MSE) as before (optional)
mse_lpr <- mean((df$y - p$fit)^2)
print(mse_lpr)
# Plot the data with error bars, the regression line, and the confidence band
ggplot(data = df, mapping = aes(x = x, y = y)) +
geom_errorbar(aes(ymin = y - e, ymax = y + e), width = 0.1, color = "blue") +
geom_point(color = "firebrick") +
geom_line(aes(y = p$fit), color = "red", size = 1) +
geom_line(aes(x = lpr.out$x, y = p$fit + p$se.fit), color = "purple", linetype = "dashed") +
geom_line(aes(x = lpr.out$x, y = p$fit - p$se.fit), color = "purple", linetype = "dashed") +
ggtitle("Local Polynomial Regression with Confidence Band") +
theme_minimal()
# REPLACE ME WITH CODE
set.seed(10)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out, data = df)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
set.seed(10)
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out, newdata = df)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
model <- lm(y ~ poly(x, 3, raw = TRUE), data = df, weights = 1 / (e^2))
# Get model predictions
df$y_pred <- predict(model, newdata = df)
# Calculate mean squared error (MSE)
mse <- mean((df$y - df$y_pred)^2)
# Extract model coefficients
coefficients <- coef(model)
# Plotting the data points with error bars and the regression line
ggplot(data = df, mapping = aes(x = x, y = y)) +
geom_errorbar(aes(ymin = y - e, ymax = y + e), width = .1, color = "blue") +
geom_point(color = "firebrick") +
geom_line(aes(y = y_pred), color = "darkgreen") +
labs(title = "Weighted Cubic Polynomial Regression",
subtitle = paste("Coefficients:", paste(round(coefficients, 3), collapse = ", ")),
caption = paste("Mean Squared Error:", round(mse, 3))) +
theme_minimal()
# REPLACE ME WITH CODE
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^12))
pr.pred <- predict(pr.out, newdata = df)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
set.seed(555)
x <- -5:5
y <- 0.1*x^3 - 0.5*x + 2.1 + rnorm(length(x),mean=0,sd=0.5*(1+abs(x)))
e <- 0.5*(1+abs(x))
df <- data.frame("x"=x,"y"=y,"e"=e)
suppressMessages(library(tidyverse))
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick")
# REPLACE ME WITH CODE
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^2))
pr.pred <- predict(pr.out, newdata = df)
mse <- mean((df$y-pr.pred)^2)
print(mse)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
pr.out <- lm(y~poly(x,3,raw = TRUE), data = df, weights = 1/(e^2))
pr.pred <- predict(pr.out, newdata = df)
mse <- mean((df$y-pr.pred)^2)
print(mse)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Cubic Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
suppressMessages(library(splines))
set.seed(1)
pr.out <- lm(y~bs(x,df = 4), data = df, weights = 1/(e^2))
pr.pred <- predict(pr.out)
mse <- mean((df$y-pr.pred)^2)
print(mse)
data.frame("Estimate"=
summary(pr.out)$coefficients[,1])
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = pr.pred), color = "red", size = 1) +
ggtitle("Polynomial Regression with four degrees of freedom") +
theme_minimal()
# REPLACE ME WITH CODE
ss.out <- suppressWarnings(
smooth.spline(df$x,y=df$y,w=1/(df$e^2),cv=TRUE)
)
ss.out$lambda
ss.pred <- predict(ss.out)
mean((y-ss.pred$y)^2)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = ss.pred$y), color = "red", size = 1) +
ggtitle("Smoothing Splines") +
theme_minimal()
# REPLACE ME WITH CODE
lpr.out <- loess(y~x,data=df,weights=1/(df$e)^2,span=0.6)
lpr.pred <- predict(lpr.out)
mse_lpr <- mean((df$y - lpr.pred)^2)
print(mse_lpr)
# Plot the data with the regression line
ggplot(data=df,mapping=aes(x=x,y=y)) +
geom_errorbar(aes(ymin=y-e, ymax=y+e), width=.1,color="blue") +
geom_point(color="firebrick") +
geom_line(aes(y = lpr.pred), color = "red", size = 1) +
ggtitle("Local Polynomial Regression") +
theme_minimal()
# REPLACE ME WITH CODE
p <- predict(lpr.out,se=TRUE)
# Compute Mean Squared Error (MSE) as before (optional)
mse_lpr <- mean((df$y - p$fit)^2)
print(mse_lpr)
# Plot the data with error bars, the regression line, and the confidence band
ggplot(data = df, mapping = aes(x = x, y = y)) +
geom_errorbar(aes(ymin = y - e, ymax = y + e), width = 0.1, color = "blue") +
geom_point(color = "firebrick") +
geom_line(aes(y = p$fit), color = "red", size = 1) +
geom_line(aes(x = lpr.out$x, y = p$fit + p$se.fit), color = "purple", linetype = "dashed") +
geom_line(aes(x = lpr.out$x, y = p$fit - p$se.fit), color = "purple", linetype = "dashed") +
ggtitle("Local Polynomial Regression with Confidence Band") +
theme_minimal()
