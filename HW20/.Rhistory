# FILL ME IN!
df <- read.csv("creditDefault.csv")
# FILL ME IN!
df <- read.csv("creditDefault.csv")
df
suppressMessages(library(corrplot))
df.numeric <- df %>% select_if(is.numeric)
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Term GPA", addCoef.col = "black", number.cex = 0.7)
# FILL ME IN!
df <- read.csv("creditDefault.csv", stringsAsFactors = TRUE)
df
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Term GPA", addCoef.col = "black", number.cex = 0.7)
# Load necessary libraries
library(ggplot2)
library(gridExtra) # For arranging multiple plots
# Example dataset
data <- df
# Target variable
target <- "Default" # Replace with your target variable
# Get predictor variable names
predictors <- setdiff(names(data), target)
# List to store plots
plot_list <- list()
# Loop through each predictor and create scatter plots
for (predictor in predictors) {
p <- ggplot(data, aes_string(x = predictor, y = target)) +
geom_point(color = "blue", alpha = 0.6) +
labs(title = paste("Scatter Plot:", target, "vs", predictor),
x = predictor,
y = target) +
theme_minimal()
plot_list[[predictor]] <- p
}
# Arrange all plots in a grid
do.call(grid.arrange, c(plot_list, ncol = 3)) # Adjust ncol as needed
# FILL ME IN!
df <- read.csv("creditDefault.csv", stringsAsFactors = TRUE)
summary(df)
# Check for missing values
missing_values <- colSums(is.na(df))
print("Missing Values in Each Column:")
print(missing_values)
# Check for duplicate rows
duplicates <- duplicated(df)
num_duplicates <- sum(duplicates)
print(paste("Number of Duplicate Rows:", num_duplicates))
# Load necessary library
suppressMessages(library(dplyr))
# Function to calculate Z-scores and identify outliers
calculate_z_scores <- function(df) {
num_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_numeric <- df[, num_columns]        # Select only numeric columns
# Calculate Z-scores
z_scores <- scale(df_numeric)
# Find outliers based on Z-score threshold (e.g., 3 or -3)
outliers <- apply(z_scores, 2, function(x) abs(x) > 3)
# Return rows where any column has an outlier
df_outliers <- df[apply(outliers, 1, any), ]
return(df_outliers)
}
# Run the function on the data
outlier_rows <- calculate_z_scores(df)
# Display rows with outliers
print("Rows with Outliers:")
print(outlier_rows)
# Load necessary libraries
library(ggplot2)
library(gridExtra) # For arranging multiple plots
# Example dataset
data <- df
# Target variable
target <- "Default" # Replace with your target variable
# Get predictor variable names
predictors <- setdiff(names(data), target)
# List to store plots
plot_list <- list()
# Loop through each predictor and create scatter plots
for (predictor in predictors) {
p <- ggplot(data, aes_string(x = predictor, y = target)) +
geom_point(color = "blue", alpha = 0.6) +
labs(title = paste("Scatter Plot:", target, "vs", predictor),
x = predictor,
y = target) +
theme_minimal()
plot_list[[predictor]] <- p
}
# Arrange all plots in a grid
do.call(grid.arrange, c(plot_list, ncol = 3)) # Adjust ncol as needed
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Term GPA", addCoef.col = "black", number.cex = 0.7)
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Default", addCoef.col = "black", number.cex = 0.7)
# Calculate correlation matrix for numeric columns only
df.numeric <- df %>% select_if(is.numeric)
# Calculate correlation matrix
corr_matrix <- cor(df.numeric, use = "complete.obs")
# Plot the correlation matrix
corrplot(corr_matrix,
method = "color",
type = "lower",
tl.cex = 0.8,
tl.col = "black",
title = "Correlation Matrix",  # Adjusted title
addCoef.col = "black",
number.cex = 0.7)
# Optionally, check how 'Default' relates to numeric variables
df %>%
group_by(Default) %>%
summarize(across(where(is.numeric), list(mean = mean, median = median), na.rm = TRUE))
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Default", addCoef.col = "black", number.cex = 0.7)
# Load ggplot2 for visualization
library(ggplot2)
# Box plot for Balance by Default
ggplot(df, aes(x = Default, y = Balance)) +
geom_boxplot() +
ggtitle("Boxplot of Balance by Default") +
xlab("Default") +
ylab("Balance")
# Box plot for Income by Default
ggplot(df, aes(x = Default, y = Income)) +
geom_boxplot() +
ggtitle("Boxplot of Income by Default") +
xlab("Default") +
ylab("Income")
# T-test for Balance by Default
t_test_balance <- t.test(Balance ~ Default, data = df)
print(t_test_balance)
# T-test for Income by Default
t_test_income <- t.test(Income ~ Default, data = df)
print(t_test_income)
# Load required library
suppressMessages(library(randomForest))
# Ensure Default is a factor
df$Default <- as.factor(df$Default)
# Train Random Forest Model
rf_model <- randomForest(Default ~ Balance + Income + Student,
data = df,
importance = TRUE,
ntree = 500)
# Print feature importance
importance_matrix <- importance(rf_model)
print("Feature Importance:")
print(importance_matrix)
# Plot feature importance
varImpPlot(rf_model,
main = "Random Forest Feature Importance")
# Load required library
suppressMessages(library(caret))
# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$Default, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
# Train Random Forest model
rf_model <- randomForest(Default ~ Balance + Income + Student,
data = train_data,
importance = TRUE,
ntree = 500)
# Predict on test data
rf_predictions <- predict(rf_model, test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(rf_predictions, test_data$Default)
print("Confusion Matrix:")
print(conf_matrix)
# Model Accuracy
# Load required library
suppressMessages(library(caret))
# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$Default, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
# Train Random Forest model
rf_model <- randomForest(Default ~ Balance + Income + Student,
data = train_data,
importance = TRUE,
ntree = 500)
# Predict on test data
rf_predictions <- predict(rf_model, test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(rf_predictions, test_data$Default)
print("Confusion Matrix:")
print(conf_matrix)
# Model Accuracy
rf_accuracy <- conf_matrix$overall['Accuracy']
print(paste("Random Forest Accuracy:", round(rf_accuracy, 4)))
# Load xgboost
suppressMessages(library(xgboost))
# Convert Default to binary (0 for No, 1 for Yes)
train_data$Default_binary <- ifelse(train_data$Default == "Yes", 1, 0)
test_data$Default_binary <- ifelse(test_data$Default == "Yes", 1, 0)
# Prepare data for xgboost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, c("Balance", "Income", "Student")]),
label = train_data$Default_binary)
# FILL ME IN!
df <- read.csv("creditDefault.csv", stringsAsFactors = TRUE)
summary(df)
# Check for missing values
missing_values <- colSums(is.na(df))
print("Missing Values in Each Column:")
print(missing_values)
# Check for duplicate rows
duplicates <- duplicated(df)
num_duplicates <- sum(duplicates)
print(paste("Number of Duplicate Rows:", num_duplicates))
# Load necessary library
suppressMessages(library(dplyr))
# Function to calculate Z-scores and identify outliers
calculate_z_scores <- function(df) {
num_columns <- sapply(df, is.numeric)  # Identify numeric columns
df_numeric <- df[, num_columns]        # Select only numeric columns
# Calculate Z-scores
z_scores <- scale(df_numeric)
# Find outliers based on Z-score threshold (e.g., 3 or -3)
outliers <- apply(z_scores, 2, function(x) abs(x) > 3)
# Return rows where any column has an outlier
df_outliers <- df[apply(outliers, 1, any), ]
return(df_outliers)
}
# Run the function on the data
outlier_rows <- calculate_z_scores(df)
# Display rows with outliers
print("Rows with Outliers:")
print(outlier_rows)
# Load necessary libraries
library(ggplot2)
library(gridExtra) # For arranging multiple plots
# Example dataset
data <- df
# Target variable
target <- "Default" # Replace with your target variable
# Get predictor variable names
predictors <- setdiff(names(data), target)
# List to store plots
plot_list <- list()
# Loop through each predictor and create scatter plots
for (predictor in predictors) {
p <- ggplot(data, aes_string(x = predictor, y = target)) +
geom_point(color = "blue", alpha = 0.6) +
labs(title = paste("Scatter Plot:", target, "vs", predictor),
x = predictor,
y = target) +
theme_minimal()
plot_list[[predictor]] <- p
}
# Arrange all plots in a grid
do.call(grid.arrange, c(plot_list, ncol = 3)) # Adjust ncol as needed
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black",
title = "Correlation Matrix with Default", addCoef.col = "black", number.cex = 0.7)
# Load ggplot2 for visualization
library(ggplot2)
# Box plot for Balance by Default
ggplot(df, aes(x = Default, y = Balance)) +
geom_boxplot() +
ggtitle("Boxplot of Balance by Default") +
xlab("Default") +
ylab("Balance")
# Box plot for Income by Default
ggplot(df, aes(x = Default, y = Income)) +
geom_boxplot() +
ggtitle("Boxplot of Income by Default") +
xlab("Default") +
ylab("Income")
# T-test for Balance by Default
t_test_balance <- t.test(Balance ~ Default, data = df)
print(t_test_balance)
# T-test for Income by Default
t_test_income <- t.test(Income ~ Default, data = df)
print(t_test_income)
# Load required library
suppressMessages(library(randomForest))
# Ensure Default is a factor
df$Default <- as.factor(df$Default)
# Train Random Forest Model
rf_model <- randomForest(Default ~ Balance + Income + Student,
data = df,
importance = TRUE,
ntree = 500)
# Print feature importance
importance_matrix <- importance(rf_model)
print("Feature Importance:")
print(importance_matrix)
# Plot feature importance
varImpPlot(rf_model,
main = "Random Forest Feature Importance")
# Load required library
suppressMessages(library(caret))
# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$Default, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
# Train Random Forest model
rf_model <- randomForest(Default ~ Balance + Income + Student,
data = train_data,
importance = TRUE,
ntree = 500)
# Predict on test data
rf_predictions <- predict(rf_model, test_data)
# Confusion Matrix
conf_matrix <- confusionMatrix(rf_predictions, test_data$Default)
print("Confusion Matrix:")
print(conf_matrix)
# Model Accuracy
rf_accuracy <- conf_matrix$overall['Accuracy']
print(paste("Random Forest Accuracy:", round(rf_accuracy, 4)))
# Load xgboost
suppressMessages(library(xgboost))
# Convert Default to binary (0 for No, 1 for Yes)
train_data$Default_binary <- ifelse(train_data$Default == "Yes", 1, 0)
test_data$Default_binary <- ifelse(test_data$Default == "Yes", 1, 0)
# Prepare data for xgboost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data[, c("Balance", "Income", "Student")]),
label = train_data$Default_binary)
# Load required libraries
suppressMessages(library(xgboost))
suppressMessages(library(caret))
# Convert Default to binary (0 for No, 1 for Yes)
train_data$Default_binary <- ifelse(train_data$Default == "Yes", 1, 0)
test_data$Default_binary <- ifelse(test_data$Default == "Yes", 1, 0)
# One-hot encode the Student variable
train_data_onehot <- model.matrix(~ Student + Balance + Income - 1, data = train_data)
test_data_onehot <- model.matrix(~ Student + Balance + Income - 1, data = test_data)
# Prepare data for xgboost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data_onehot),
label = train_data$Default_binary)
test_matrix <- xgb.DMatrix(data = as.matrix(test_data_onehot),
label = test_data$Default_binary)
# Train xgboost model
xgb_model <- xgboost(data = train_matrix,
objective = "binary:logistic",
nrounds = 100,
verbose = 0)
# Predict on test data
xgb_predictions <- predict(xgb_model, test_matrix)
xgb_class_predictions <- ifelse(xgb_predictions > 0.5, "Yes", "No")
# Confusion Matrix for Gradient Boosting
xgb_conf_matrix <- confusionMatrix(as.factor(xgb_class_predictions), test_data$Default)
print("Confusion Matrix (Gradient Boosting):")
print(xgb_conf_matrix)
# Model Accuracy
xgb_accuracy <- xgb_conf_matrix$overall['Accuracy']
print(paste("Gradient Boosting Accuracy:", round(xgb_accuracy, 4)))
