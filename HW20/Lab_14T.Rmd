---
title: "Lab: Data Analysis Workflow Review"
author: "36-600"
output:
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
  pdf_document:
    toc: no
---

This week's lab is very much do-it-yourself. On `Canvas`, under `Files > DATA`, there is a file called `creditDefault.csv`. Your boss wants to know if any of the variables included in this file, apart from `Default` itself, are important for predicting whether a person will default rather than paying back their credit-card balance.

From the information above, you should construct an appropriate answer. Note that regardless of whether you think a non-ML model is sufficient, you should always check to see if an ML model gives much better predictive results. Also note that your boss is not necessarily looking for plots here...but you'd always want to do *some* EDA, if for no other reason than to ensure you don't have missing data or outliers!

EDA
```{r}
# FILL ME IN!
df <- read.csv("creditDefault.csv", stringsAsFactors = TRUE)
summary(df)
```
Check for missing values and duplicates
```{r}
# Check for missing values
missing_values <- colSums(is.na(df))
print("Missing Values in Each Column:")
print(missing_values)

# Check for duplicate rows
duplicates <- duplicated(df)
num_duplicates <- sum(duplicates)
print(paste("Number of Duplicate Rows:", num_duplicates))
```
Check for Outliers
```{r}
# Load necessary library
suppressMessages(library(dplyr))

# Function to calculate Z-scores and identify outliers
calculate_z_scores <- function(df) {
  num_columns <- sapply(df, is.numeric)  # Identify numeric columns
  df_numeric <- df[, num_columns]        # Select only numeric columns
  
  # Calculate Z-scores
  z_scores <- scale(df_numeric)
  
  # Find outliers based on Z-score threshold (e.g., 3 or -3)
  outliers <- apply(z_scores, 2, function(x) abs(x) > 3)
  
  # Return rows where any column has an outlier
  df_outliers <- df[apply(outliers, 1, any), ]
  
  return(df_outliers)
}

# Run the function on the data
outlier_rows <- calculate_z_scores(df)

# Display rows with outliers
print("Rows with Outliers:")
print(outlier_rows)
```

Assess the balance of the Default target variable
```{r}
# Load necessary libraries
library(ggplot2)
library(gridExtra) # For arranging multiple plots

# Example dataset
data <- df

# Target variable
target <- "Default" # Replace with your target variable

# Get predictor variable names
predictors <- setdiff(names(data), target)

# List to store plots
plot_list <- list()

# Loop through each predictor and create scatter plots
for (predictor in predictors) {
  p <- ggplot(data, aes_string(x = predictor, y = target)) +
    geom_point(color = "blue", alpha = 0.6) +
    labs(title = paste("Scatter Plot:", target, "vs", predictor),
         x = predictor,
         y = target) +
    theme_minimal()
  plot_list[[predictor]] <- p
}

# Arrange all plots in a grid
do.call(grid.arrange, c(plot_list, ncol = 3)) # Adjust ncol as needed
```

Feature Importance
Correlation Analysis for numerical columns
```{r}
suppressMessages(library(corrplot))
suppressMessages(library(dplyr))
df.numeric <- df %>% select_if(is.numeric)
corr_matrix <- cor(df.numeric, use = "complete.obs")
corrplot(corr_matrix, method = "color", type = "lower", tl.cex = 0.8, tl.col = "black", 
         title = "Correlation Matrix with Default", addCoef.col = "black", number.cex = 0.7)
```
Visualising relationships
```{r}
# Load ggplot2 for visualization
library(ggplot2)

# Box plot for Balance by Default
ggplot(df, aes(x = Default, y = Balance)) +
  geom_boxplot() +
  ggtitle("Boxplot of Balance by Default") +
  xlab("Default") +
  ylab("Balance")

# Box plot for Income by Default
ggplot(df, aes(x = Default, y = Income)) +
  geom_boxplot() +
  ggtitle("Boxplot of Income by Default") +
  xlab("Default") +
  ylab("Income")
```
Statistical tests:
```{r}
# T-test for Balance by Default
t_test_balance <- t.test(Balance ~ Default, data = df)
print(t_test_balance)

# T-test for Income by Default
t_test_income <- t.test(Income ~ Default, data = df)
print(t_test_income)
```
The t-test shows that the mean Balance for individuals who defaulted (Yes) is significantly higher than for those who did not (No). This is confirmed by the very low p-value, which indicates that the difference in means is statistically significant.

The t-test for Income shows that there is no significant difference in mean income between those who defaulted and those who did not, as the p-value is above the typical significance threshold of 0.05.

Conclusion: Balance is a stronger indicator than income for predicting defaults.

Feature Importance with ML models:
Random Forest
```{r}
# Load required library
suppressMessages(library(randomForest))

# Ensure Default is a factor
df$Default <- as.factor(df$Default)

# Train Random Forest Model
rf_model <- randomForest(Default ~ Balance + Income + Student, 
                         data = df, 
                         importance = TRUE, 
                         ntree = 500)

# Print feature importance
importance_matrix <- importance(rf_model)
print("Feature Importance:")
print(importance_matrix)

# Plot feature importance
varImpPlot(rf_model, 
           main = "Random Forest Feature Importance")
```
Balance is the most important feature by far for predicting whether a person will default. Both metrics (Mean Decrease Accuracy and Gini) strongly support this.
Income and Student have much lower importance, suggesting they contribute far less to predicting Default.

Evaluate RF performance
```{r}
# Load required library
suppressMessages(library(caret))

# Split data into training and testing sets
set.seed(123)  # For reproducibility
train_index <- createDataPartition(df$Default, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]

# Train Random Forest model
rf_model <- randomForest(Default ~ Balance + Income + Student, 
                         data = train_data, 
                         importance = TRUE, 
                         ntree = 500)

# Predict on test data
rf_predictions <- predict(rf_model, test_data)

# Confusion Matrix
conf_matrix <- confusionMatrix(rf_predictions, test_data$Default)
print("Confusion Matrix:")
print(conf_matrix)

# Model Accuracy
rf_accuracy <- conf_matrix$overall['Accuracy']
print(paste("Random Forest Accuracy:", round(rf_accuracy, 4)))
```
The model is very good at identifying non-defaults (No), with high sensitivity and PPV.
It has a moderate performance for identifying defaults (Yes), as seen in the lower specificity.
Overall, the accuracy and other metrics indicate a well-performing model.

Gradient Boosting
```{r}
# Load required libraries
suppressMessages(library(xgboost))
suppressMessages(library(caret))

# Convert Default to binary (0 for No, 1 for Yes)
train_data$Default_binary <- ifelse(train_data$Default == "Yes", 1, 0)
test_data$Default_binary <- ifelse(test_data$Default == "Yes", 1, 0)

# One-hot encode the Student variable
train_data_onehot <- model.matrix(~ Student + Balance + Income - 1, data = train_data)
test_data_onehot <- model.matrix(~ Student + Balance + Income - 1, data = test_data)

# Prepare data for xgboost
train_matrix <- xgb.DMatrix(data = as.matrix(train_data_onehot),
                            label = train_data$Default_binary)
test_matrix <- xgb.DMatrix(data = as.matrix(test_data_onehot),
                           label = test_data$Default_binary)

# Train xgboost model
xgb_model <- xgboost(data = train_matrix, 
                     objective = "binary:logistic", 
                     nrounds = 100, 
                     verbose = 0)

# Predict on test data
xgb_predictions <- predict(xgb_model, test_matrix)
xgb_class_predictions <- ifelse(xgb_predictions > 0.5, "Yes", "No")

# Confusion Matrix for Gradient Boosting
xgb_conf_matrix <- confusionMatrix(as.factor(xgb_class_predictions), test_data$Default)
print("Confusion Matrix (Gradient Boosting):")
print(xgb_conf_matrix)

# Model Accuracy
xgb_accuracy <- xgb_conf_matrix$overall['Accuracy']
print(paste("Gradient Boosting Accuracy:", round(xgb_accuracy, 4)))
```
Both models perform well, but Random Forest has a slight edge in overall accuracy and sensitivity.
Gradient Boosting provides comparable results with better performance on the minority class (Yes), as evidenced by slightly higher specificity.

Conclusion:
Balance is the most critical predictor of whether a person will default on their credit-card balance.
Income has some predictive power but is less influential than Balance.
The Student variable is the least important among the predictors.
Both Random Forest and Gradient Boosting models demonstrate that ML provides substantial predictive value beyond traditional statistical methods.