---
title: "Lab: Machine Learning + Trees"
author: "36-600"
output: 
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
---

To answer the questions below, it will help you to refer to the class notes and to Sections 8.1 and 8.3.1-8.3.2 of ISLR 1ed. *Note, however, that we use the rpart package to create trees, which ISLR does not use.* So ISLR is best used for looking up background details.

# Regression Trees

## Data, Part I

We'll begin by importing the heart-disease dataset and log-transforming the response variable, `Cost`:
```{r}
df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
summary(df)
```

## Question 1

Split the data into training and test sets. Call these `df.train` and `df.test`. Reuse the random number seed that you used when splitting the data prior to learning the multiple linear regression model in a previous lab.
```{r}
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(0.7 * length(df$Cost)))
df.train <- df[s,]
df.test <- df[-s,]
```

## Question 2

Learn a regression tree model and report the test-set MSE. How does this MSE compare with what you observed for the linear model? Is it lower? If so, then the (inherently more flexible) nonlinear regression tree model is adapting better to the geometry of the data than the (inherently less flexible) linear model...with the tradeoff that inferential ability is reduced. (But not eliminated, as we'll see.)
```{r}
# REPLACE ME WITH CODE
library(rpart)
rpart.out <- rpart(Cost~.,data=df.train)
predictions <- predict(rpart.out, newdata = df.test)
mse_tree <- mean((df.test$Cost - predictions)^2)
mse_tree
```
```
Replace me with text
The Mean Squared Error (MSE) for the logistic regression model is 1.659426, indicating that, on average, the predicted values deviate from the actual values by this amount. In contrast, the regression tree model demonstrates a lower MSE of 1.3758, suggesting that it provides more accurate predictions for the test set compared to the logistic regression model.
```

## Question 3

Visualize the tree. Install the package `rpart.plot` and run its namesake function while inputting the results of your tree fit. If you were of a mind to do inference, you'd look to see what variables lie at the top of the tree: these are presumably the ones with the most statistical information. (Note that because this is a regression tree, the `extra` argument to `rpart.plot()` won't be useful here and you can leave it out of the function call.)
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
library(rpart.plot)
rpart.plot(rpart.out)
```

## Question 4

Create a diagnostic plot, specifically, the test-set predicted responses ($y$-axis) versus the test-set observed responses ($x$-axis). The predictions were generated in Question 2. For enhanced readability, be sure to set the $x$ limits and the $y$ limits to be the same, and add a line of slope one to the plot. Does the plot seem strange to you? If so, and you don't know what is going on, call us over.
```{r fig.align='center',fig.height=4,fig.width=4}
# REPLACE ME WITH CODE
# Define limits based on the observed and predicted range
lims <- range(c(predictions, df.test$Cost))

# Create the plot
plot(df.test$Cost, predictions, 
     xlim = lims, ylim = lims, 
     xlab = "Observed Cost", ylab = "Predicted Cost", 
     main = "Diagnostic Plot: Observed vs. Predicted Costs")
abline(a = 0, b = 1, col = "red", lty = 2)  # Line with slope 1
```

## Question 5

Run `plotcp()` with the output of your call to `rplot()` to see if the tree needs pruned. (Yes, it should be "needs to be pruned," but you're in Pittsburgh.) As a reminder, you are looking for the leftmost point that lies below the dotted line. If this is not the last point (the point farthest to the right), then `plotcp()` is trying to tell you to prune the tree. Note that depending on how you split the data, you may or may not see evidence that pruning is necessary.

Note that even if pruning is deemed necessary, you do not need to do that pruning here. You would, if necessary, go back to the code given in today's notes to extract the pruned tree, which you can then use to, e.g., compute an MSE.
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
plotcp(rpart.out)
```

---

# Classification Trees

Now we turn our attention to classification trees.

## Data, Part II

We will now load in the data on political movements that you looked at in the logistic regression lab:
```{r}
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
  n               <- length(variable)
  new.variable    <- rep(level0,n)
  w               <- which(variable==1)
  new.variable[w] <- level1
  return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
```

## Question 6

Split the data! If you can, match what you did in the logistic regression lab (as far as seed-setting is concerned).
```{r}
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))

df.train <- df[s,]
df.test <- df[-s,]
```

## Question 7

Your next job is to learn a classification tree. Do that, and output a confusion matrix. (Note that the use of the `predict()` function might be, for you, a little different here: use `type="class"` as an argument, so that the output is not a probability but a classification. You can use the output directly when creating the confusion matrix.) What is the misclassification rate? (If you split your data in the same manner as you did for linear regression, is the MCR lower? Just make a mental note.)
```{r}
# REPLACE ME WITH CODE
rpart.out <- rpart(label ~.,data = df.train , method = "class")
predictions <- predict(rpart.out , newdata = df.test , type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = df.test$label)
print(conf_matrix)

# Misclassification rate
mcr <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
mcr
```
```
Replace me with text
The MCR for linear regression with the same seed was 0.4. So, it is lower for classification trees by 0.04
This suggests that the regression tree model performs better in accurately classifying the data than the logistic regression model.
```

## Question 8

Let's compute the Area Under Curve (AUC) for the decision tree model. Dealing with prediction is a bit tricky as the argument change a bit from model to model, but what you'd want to do here is run

- resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]

and then mimic the material presented in the notes to generate an AUC.
```{r}
# REPLACE ME WITH CODE
library(pROC)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
# Compute AUC
roc_obj <- roc(df.test$label, resp.pred, levels = c("FAILURE", "SUCCESS"))
auc_value <- auc(roc_obj)
auc_value
plot(roc_obj, main = "ROC Curve for Decision Tree Model", col = "blue", lwd = 2)
```

## Question 9

Plot your classification tree (perhaps with the argument `extra=104` or `extra=106`) and determine if pruning is necessary using `plotcp()`. Make a mental note about the pruning...but see Question 10.
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
rpart.plot(rpart.out , extra = 104)
# Plot the complexity parameter to assess if pruning is needed
plotcp(rpart.out)
```

## Question 10

Here, I suspect you saw clear evidence that pruning would be useful. Go ahead, prune the tree and replot the pruned tree. Also, compute the misclassification rate: did pruning make things worse?
```{r fig.align='center',fig.width=4,fig.height=4}
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(rpart.out$cptable[, "xerror"]), "CP"]
rpart.pruned <- prune(rpart.out,cp=optimal_cp)

# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)

# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "class")

pruned_conf_matrix <- table(Predicted = class.prob, Actual = df.test$label)
print(pruned_conf_matrix)

# Calculate misclassification rate
pruned_mcr <- 1 - sum(diag(pruned_conf_matrix)) / sum(pruned_conf_matrix)
print(paste("Misclassification Rate after Pruning:", round(pruned_mcr, 3)))
```
```
Replace me with text
Pruning the classification tree led to a slight increase in the misclassification rate, from 36.9% to 40%. This suggests that while pruning simplified the model, it may have sacrificed some predictive accuracy. The trade-off implies the pruned tree is easier to interpret, though slightly less effective in classifying new data correctly.
```
