df      <- read.csv("http://www.stat.cmu.edu/~pfreeman/heart_disease.csv",stringsAsFactors=TRUE)
df      <- df[,-10]
w       <- which(df$Cost > 0)
df      <- df[w,]
df$Cost <- log(df$Cost)
summary(df)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$Cost) , round(0.7 * length(df$Cost)))
df.train <- df[s,]
df.test <- df[-s,]
install.packages("rpart")
# REPLACE ME WITH CODE
library(rpart)
rpart.out <- rpart(Cost~.,data=df.train)
predictions <- predict(tree_model, newdata = df.test)
# REPLACE ME WITH CODE
library(rpart)
rpart.out <- rpart(Cost~.,data=df.train)
predictions <- predict(rpart.out, newdata = df.test)
mse_tree <- mean((df.test$Cost - predictions)^2)
mse_tree
install.packages("rpart.plot")
?rpart.plot()
# REPLACE ME WITH CODE
library(rplot)
# REPLACE ME WITH CODE
library(rplot.plot)
# REPLACE ME WITH CODE
library(rpart.plot)
#rpart.plot(rpart.out,extra=104)
?rpart.plot()
# REPLACE ME WITH CODE
library(rpart.plot)
rpart.plot(rpart.out,extra=104)
# REPLACE ME WITH CODE
library(rpart.plot)
rpart.plot(rpart.out)
# REPLACE ME WITH CODE
# Define limits based on the observed and predicted range
lims <- range(c(predictions, df.test$Cost))
# Create the plot
plot(df.test$Cost, predictions,
xlim = lims, ylim = lims,
xlab = "Observed Cost", ylab = "Predicted Cost",
main = "Diagnostic Plot: Observed vs. Predicted Costs")
abline(a = 0, b = 1, col = "red", lty = 2)  # Line with slope 1
# REPLACE ME WITH CODE
plotcp(rpart.out)
load(url("http://www.stat.cmu.edu/~pfreeman/movement.Rdata"))
f <- function(variable,level0="NO",level1="YES") {
n               <- length(variable)
new.variable    <- rep(level0,n)
w               <- which(variable==1)
new.variable[w] <- level1
return(factor(new.variable))
}
predictors$nonviol      <- f(predictors$nonviol)
predictors$sanctions    <- f(predictors$sanctions)
predictors$aid          <- f(predictors$aid)
predictors$support      <- f(predictors$support)
predictors$viol.repress <- f(predictors$viol.repress)
predictors$defect       <- f(predictors$defect)
levels(response)        <- c("FAILURE","SUCCESS")
df           <- cbind(predictors,response)
names(df)[9] <- "label"
rm(id.half,id,predictors.half,predictors,response)
# REPLACE ME WITH CODE
set.seed(100)
s <- sample(length(df$label) , round(0.7*length(df$label)))
df.train <- df[s,]
df.test <- df[-s,]
# REPLACE ME WITH CODE
rpart.out <- rpart(label ~.,data = df.train)
predictions <- predict(rpart.out , newdata = df.test)
# REPLACE ME WITH CODE
rpart.out <- rpart(label ~.,data = df.train , method = "class")
predictions <- predict(rpart.out , newdata = df.test , type = "class")
# Confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = df.test$label)
print(conf_matrix)
# Misclassification rate
mcr <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
mcr
# REPLACE ME WITH CODE
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
class.pred <- ifelse(resp.pred>0.5,"SUCCESS","FAILURE")
round(mean(class.pred!=df.test$class),3)
install.packages("pROC")
# REPLACE ME WITH CODE
library(pROC)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
# Compute AUC
roc_obj <- roc(df.test$label, resp.pred)
auc_value <- auc(roc_obj)
auc_value
# REPLACE ME WITH CODE
rpart.plot(rpart.out , extra = 104)
# REPLACE ME WITH CODE
rpart.plot(rpart.out , extra = 104)
# Plot the complexity parameter to assess if pruning is needed
plotcp(rpart.out)
# REPLACE ME WITH CODE
rpart.pruned <- prune(rpart.out,cp=0.045)
# REPLACE ME WITH CODE
rpart.pruned <- prune(rpart.out,cp=0.045)
class.prob <- predict(rpart.pruned,newdata=df.test,type="prob")[,2]
class.pred <- ifelse(class.prob>0.5,"STAR","GALAXY")
round(mean(class.pred!=df.test$class),3)
# REPLACE ME WITH CODE
rpart.pruned <- prune(rpart.out,cp=0.045)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# REPLACE ME WITH CODE
rpart.pruned <- prune(rpart.out,cp=0.045)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "prob")[,2]
# Convert probabilities to class labels with a threshold of 0.5
class.pred <- ifelse(class.prob > 0.5, "STAR", "GALAXY")
# Calculate misclassification rate
mcr_pruned <- mean(class.pred != df.test$class)
round(mcr_pruned, 3)
# REPLACE ME WITH CODE
library(pROC)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
# Compute AUC
roc_obj <- roc(df.test$label, resp.pred, levels = c("FAILURE", "SUCCESS"))
auc_value <- auc(roc_obj)
auc_value
# REPLACE ME WITH CODE
library(pROC)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
# Compute AUC
roc_obj <- roc(df.test$label, resp.pred, levels = c("FAILURE", "SUCCESS"))
auc_value <- auc(roc_obj)
auc_value
plot(roc_curve, main = "ROC Curve for Decision Tree Model", col = "blue", lwd = 2)
# REPLACE ME WITH CODE
library(pROC)
resp.pred <- predict(rpart.out,newdata=df.test,type="prob")[,2]
# Compute AUC
roc_obj <- roc(df.test$label, resp.pred, levels = c("FAILURE", "SUCCESS"))
auc_value <- auc(roc_obj)
auc_value
plot(roc_obj, main = "ROC Curve for Decision Tree Model", col = "blue", lwd = 2)
# REPLACE ME WITH CODE
optimal_cp <- tree_model$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(tree_model$cptable[, "xerror"]), "CP"]
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(rpart.out$cptable[, "xerror"]), "CP"]
rpart.pruned <- prune(rpart.out,cp=optimal_cp)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "class")[,2]
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(rpart.out$cptable[, "xerror"]), "CP"]
rpart.pruned <- prune(rpart.out,cp=optimal_cp)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "prob")[,2]
pruned_conf_matrix <- table(Predicted = class.prob, Actual = df.test$label)
print(pruned_conf_matrix)
# Calculate misclassification rate
pruned_mcr <- 1 - sum(diag(pruned_conf_matrix)) / sum(pruned_conf_matrix)
print(paste("Misclassification Rate after Pruning:", round(pruned_mcr, 3)))
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(rpart.out$cptable[, "xerror"]), "CP"]
rpart.pruned <- prune(rpart.out,cp=optimal_cp)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "class")[,2]
# REPLACE ME WITH CODE
optimal_cp <- rpart.out$cptable[which.min(rpart.out$cptable[, "xerror"]), "CP"]
rpart.pruned <- prune(rpart.out,cp=optimal_cp)
# Plot the pruned tree
rpart.plot(rpart.pruned, extra = 104)
# Predict class probabilities on the test set
class.prob <- predict(rpart.pruned, newdata = df.test, type = "class")
pruned_conf_matrix <- table(Predicted = class.prob, Actual = df.test$label)
print(pruned_conf_matrix)
# Calculate misclassification rate
pruned_mcr <- 1 - sum(diag(pruned_conf_matrix)) / sum(pruned_conf_matrix)
print(paste("Misclassification Rate after Pruning:", round(pruned_mcr, 3)))
