---
title: "Lab: Random Effects"
author: "36-600"
output:
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
  pdf_document:
    toc: no
---

Today's lab will be relatively short, so that you can turn it in and head off to fall break.

## Data

Here we read in the sleep study data from Project 1 and we retain three variables:
`cohort` and `term_gpa` as predictors, and `TotalSleepTime` (renamed `sleep`) as the 
response.
```{r}
suppressMessages(library(tidyverse))
df        <- read.csv(url("https://www.stat.cmu.edu/~pfreeman/cmu-sleep.csv"))
df$cohort <- factor(df$cohort)
df %>% select(.,cohort,TotalSleepTime,term_gpa) -> df
names(df)[2] <- "sleep"
summary(df)
```

Note that in this lab, we are not going to split the data into training and test sets.

## Question 1

Let's first assume that we regress `sleep` upon `cohort`. Since the cohorts that appear
in the study are a randomly selected subset of all possible cohorts, pursuing learning a
random effects model is appropriate (as opposed to a one-way ANOVA model). Learn an 
appropriate model using `lmer()` and pass the output to `summary()`. Display the five
intercepts for the five cohorts. (Hint: utilize one of the functions shown in the notes,
one specifically used with the Palmer Penguin data.) Last, what is the
within-cohort correlation? (This last part involves extracting numbers from the
`summary()` output and "doing math" as opposed to making further function calls.) Is
this a weak, medium, or strong correlation? (Use the internet to make that judgement. Note
that no two tables mapping correlation coefficients to adjectives seem to match.)
```{r}
suppressMessages(library(lme4))  # uncomment once the library is installed

lm.out <- lmer(sleep ~ 1 + (1 | cohort) , data = df)
summary(lm.out)
coef(lm.out)$cohort

# FILL ME IN WITH CODE
```
```
FILL ME IN WITH TEXT
With an ICC of approximately 0.078, this suggests a weak correlation between the cohort and sleep. Intra-class correlation values less than 0.1 are generally considered weak.
```

## Question 2

Now let's look at `term_gpa`. Learn a simple linear regression model that has `sleep`
as the response variable and `term_gpa` as the predictor variable, and overlay the model
on a plot of `sleep` versus `term_gpa`. Also, determine the AIC value for the model.
```{r fig.align='center',fig.height=4,fig.width=4}
# FILL ME IN WITH CODE
lm.out <- lm(sleep ~ term_gpa, data = df)

ggplot(df , aes(x = term_gpa , y = sleep)) +
  geom_point() +
  geom_smooth(method = "lm" , col = "blue")


aic_val <- AIC(lm.out)
print(aic_val)
```

## Question 3

Now implement a mixed effects model with `term_gpa` as the fixed effect and `cohort` as
the random effect, with random intercepts (but same slopes). Output the linear model coefficients for each cohort. (Mentally confirm that indeed, the intercepts
are different but the slopes are the same.) And, as you did in Q2, record the AIC value.

No plot is necessary, for now.
```{r}
# FILL ME IN WITH CODE
mixed_model <- lmer(sleep ~ term_gpa + (1 | cohort), data = df)

summary(mixed_model)

coef(mixed_model)$cohort

aic_mixed_model <- AIC(mixed_model)
aic_mixed_model
```

## Question 4

Repeat Q3, but now have random slopes with the same intercept.
```{r}
# FILL ME IN WITH CODE
mixed_model_random_slopes <- lmer(sleep ~ 1 + (term_gpa | cohort), data = df)

summary(mixed_model_random_slopes)

coef(mixed_model_random_slopes)$cohort

aic_mixed_model_random_slopes <- AIC(mixed_model_random_slopes)
aic_mixed_model_random_slopes
```

## Question 5

Repeat Q3, but now have random slopes *and* intercepts.
```{r}
# FILL ME IN WITH CODE
mixed_model_random_slopes_intercepts <- lmer(sleep ~ term_gpa + (term_gpa | cohort), data = df)

summary(mixed_model_random_slopes_intercepts)

coef(mixed_model_random_slopes_intercepts)$cohort

aic_mixed_model_random_slopes_intercepts <- AIC(mixed_model_random_slopes_intercepts)
aic_mixed_model_random_slopes_intercepts

```

## Question 6

Select the best model from among those in Q2-Q5 (i.e., the one with the lowest AIC value).
Plot the data again, and overlay the best model...note that this may require you to make
five separate calls to `geom_abline()`. Note that to access the slopes and intercepts, 
you would use, e.g.,
```
coefs <- coef(lmer.out)$cohort
coefs[1,1] # first row, first column -- intercept of first cohort
coefs[3,2] # third row, second column -- slope of third cohort
etc.
```
In the end, your plot may not show five separate lines, which is fine, because the
`lac1` and `lac2`, and `uw1` and `uw2`, cohorts had very similar data.
```{r fig.align='center',fig.height=4,fig.width=4}
# FILL ME IN WITH CODE
lm.out <- lmer(sleep ~ term_gpa + (1 | cohort) , data = df)
coefs <-  coef(lm.out)$cohort

ggplot(data=df, mapping=aes(x=term_gpa, y=sleep, color=cohort)) + 
  geom_point(alpha=0.7) +
  # lac1
  geom_abline(slope=coefs[1, 2], intercept=coefs[1, 1], col = "black") +
  # lac2
  geom_abline(slope=coefs[2, 2], intercept=coefs[2, 1], col = "seagreen") +
  # nh
  geom_abline(slope=coefs[3, 2], intercept=coefs[3, 1], col = "maroon") +
  # uw1
  geom_abline(slope=coefs[4, 2], intercept=coefs[4, 1], col = "yellow") +
  # uw2
  geom_abline(slope=coefs[5, 2], intercept=coefs[5, 1], col = "darkblue")
```

