---
title: "Lab_14T"
author: "36-600"
date: "Fall 2023"
output:
  html_document:
    toc: no
    toc_float: no
    theme: spacelab
  pdf_document:
    toc: no
---

## Data: Part I

We'll begin by importing the breast cancer dataset we've looked at previously:
```{r}
suppressMessages(library(tidyverse))
df        <- read.csv("http://www.stat.cmu.edu/~pfreeman/breastcancer.csv",stringsAsFactors=TRUE)
df        <- df[,c(1,16)]
names(df) <- c("x","Y")
summary(df)
```
We retain `Diagnosis` as our categorical predictor variable (now dubbed `x`) and `Worst.Smoothness` as
the response variable (now dubbed `Y`).

## Question 1

Create a grouped boxplot and make a mental note as to whether or not it appears that the true means for each group are different. 
```{r fig.align='center',fig.height=4,fig.width=4}
# FILL ME IN
ggplot(data = df , mapping = aes(x=x,y=Y)) + 
  geom_boxplot(fill = "Red")
```

## Question 2

Now let's determine if the assumptions underlying the use of the two-sample $t$ test hold...specifically,
that the data within the individual groups are normally distributed with constant variance $\sigma^2$.

First, run a `shapiro.test()` on the data of groups `B` and `M`. If the $p$-value is less than $\alpha = 0.05$,
we reject the null hypothesis that the data are normally distributed. (However, even if we reject the null hypothesis, we will still use these data below for illustrative purposes!)

Recall that in `dplyr` you can do the test as follows:
```
df %>% filter(.,x=="<INSERT CATEGORY NAME>") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.)
```
The `pull()` function, which is new, coerces a column of numbers in a data frame to being "just" a 
vector...which we need to do because the Shapiro-Wilk test function doesn't like data frames as inputs.

Go ahead and perform the test here, then state a conclusion.
```{r}
# FILL ME IN
df %>% filter(.,x=="B") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.) 
df %>% filter(.,x=="M") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.)
```
```
FILL ME IN
p-value for both B and M are less than 0.05. So, ideally we would reject the null hypothesis.
```

Second, run the `leveneTest()` (from the `car` package). Here, you need not separate the data...you can
simply input a model formula (`Y~x`) and specify `data=df`. If the $p$-value is less than $\alpha = 0.05$,
we reject the null hypothesis that the variances are the same across groups. What do you conclude?
(We should note a rule of thumb that you might see: two-sample $t$ tests and ANOVA are robust to
heterogeneity of variance so long as the largest variance is no more than four times the smallest variance.
So even if we reject the null here, we might very well still be able to pursue ANOVA.)
```{r}
# FILL ME IN
library(car)
leveneTest(Y~x , data = df)
```
```
FILL ME IN
From the levene test the p-value is 0.4661 which is greater than 0.05. So, we fail to reject the null hypothesis
```

## Question 3

Now, run a two-sample $t$ test and make a conclusion about whether the response values for each group
(`B` and `M`) have the same mean. Note that like for Levene's test, the `t.test()` will allow you to
input a model formula, so you don't need to split up the data yourself. The null hypothesis, by the way,
is that the difference in means is equal to zero.
```{r}
# FILL ME IN
t.test(Y~x, data = df)
```
```
FILL ME IN
The mean in group M is slightly higher than the mean in group B
```

## Data: Part II

We'll continue by importing the hospital cost dataset we've looked at previously:
```{r}
df        <- read.csv("http://www.stat.cmu.edu/~pfreeman/hospital_cost.csv",stringsAsFactors=TRUE)
df        <- df[,c(5,1)]
names(df) <- c("x","Y")
df$x      <- factor(df$x)
w         <- which(df$Y==0)
df        <- df[-w,]
df$Y      <- log10(df$Y)
summary(df)
```
We retain `Drugs` as our categorical predictor variable (now dubbed `x`) and `Cost` as
the response variable (now dubbed `Y`). The groups for `x` are "0", "1", and "2". Note
that we logarithmically transform `Y` after removing values of zero.

## Question 4

Repeat Q1 here: create a grouped boxplot and make a mental note as to whether or not it appears 
that the true means for each group are different. 
```{r fig.align='center',fig.height=4,fig.width=4}
# FILL ME IN
ggplot(data = df , mapping = aes(x=x, y=Y)) +
  geom_boxplot(fill = "blue")
```

## Question 5

Repeat Q2 here: run three Shapiro-Wilk tests and one Levene's test, and state which underlying assumptions
of the ANOVA model hold here, and which do not. If Levene's test indicates that the variances are truly unequal, compute the variances for each sample and see whether or not the rule-of-thumb given in Q2 can
be applied here. (To compute variances, just use the same "codeflow" as you
used for the Shapiro-Wilk test but put the `var()` function at the end.)
```{r}
# FILL ME IN
df %>% filter(.,x=="0") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.)
df %>% filter(.,x=="1") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.)
df %>% filter(.,x=="2") %>% select(.,Y) %>% pull(.) %>% shapiro.test(.)

leveneTest(Y~x , data = df)

df %>% filter(.,x=="0") %>% select(.,Y) %>% pull(.) %>% var()
df %>% filter(.,x=="1") %>% select(.,Y) %>% pull(.) %>% var()
df %>% filter(.,x=="2") %>% select(.,Y) %>% pull(.) %>% var()
```
```
FILL ME IN
From the Shapiro Wilk test, we can see that all of the 3 p-values are greater than 0.05. So, we fail to reject the null hypothesis.
From the levene test, p-value is less than 0.05, so we reject the null hypothesis of equal variances. The assumption of homogeneity of variances does not hold.
The ratio of highest variance to lowest variance is 1.33, which is less than 4. Therefore, the variances are not unequal. So, the difference is not substantial enough to indicate ANOVA.
```

## Question 6

Show the summary output from regressing the variable `Y` upon `x`. What is the estimated mean response
for each group?
```{r}
# FILL ME IN
lm.out <- lm(Y~x, data = df)
summary(lm.out)
```
```
FILL ME IN
The estimated mean response for group x=0 is 2.66656
The estimated mean response for group x=1 is 2.66656 + 0.30586 = 2.97242
The estimated mean response for group x=2 is 2.66656 + 0.36439 = 3.03095
```

## Question 7

Now pass the output from your call to linear regression into the `anova()` function. What is the hypothesis
test statistic value and the $p$-value, and what conclusion do you draw?
```{r}
# FILL ME IN
anova(lm.out)
```
```
FILL ME IN
The hypothesis statistic value(F value) is 12.136
Since the p value is smaller than 0.05, we reject the null hypothesis. This indicates that there is strong evidence to suggest that the means of Y is different across the groups. 
```

## Question 8

Here, pass the output from `aov(Y~x,data=df)` to the `TukeyHSD()` function and state a conclusion:
which group or groups differ from the others? Which do we conclude have the same means?
```{r}
# FILL ME IN
TukeyHSD(aov(Y~x , data = df))
```
```
FILL ME IN
Group 1-0 and 2-0 differ significantly as seen in their p-values (0.002 & 0.00019).
Group 2-1 do not have statistically significant difference as seen in their p-value(0.8778). Which means that their means are statistically the same.
```
